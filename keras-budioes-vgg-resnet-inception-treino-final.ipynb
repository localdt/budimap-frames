{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0877a678",
   "metadata": {},
   "source": [
    "# Treinamento das Redes VGGNet, ResNet e Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac9ef1",
   "metadata": {},
   "source": [
    "Código desenvolvido para o projeto de mestrado \"Aplicação de Metodologia de Aprendizado Profundo para Identificação e Classificação de Budiões\" - UNIFESP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65316dbf",
   "metadata": {},
   "source": [
    "## Declaração das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed35640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, Input, Conv2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras import Sequential\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f9967",
   "metadata": {},
   "source": [
    "## Leitura das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc3c032",
   "metadata": {},
   "source": [
    "Obtenção das imagens dos budiões já organizadas por diretório de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ec7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(pasta):\n",
    "    exts = ['.PNG','.JPG','.JPEG','.TIFF','.GIF','.BMP']\n",
    "    tot_images = 0\n",
    "    for sf in [name for name in os.listdir(pasta) if os.path.isdir(os.path.join(pasta, name))]:\n",
    "        subdir = os.path.join(pasta,sf)\n",
    "        tot_images = tot_images + len([name for name in os.listdir(subdir) if os.path.splitext(name)[1].upper() in exts])\n",
    "    return tot_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00021bf",
   "metadata": {},
   "source": [
    "## Definição de Hiper parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d20a9",
   "metadata": {},
   "source": [
    "Definição de variáveis (hiper parâmetros) usados na rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquitetura\n",
    "architecture = 'VGG'\n",
    "#architecture = 'RESNET'\n",
    "#architecture = 'INCEPTION'\n",
    "\n",
    "#Número de épocas (iterações) do treinamento\n",
    "EPOCHS = 50;\n",
    "\n",
    "#Serão gerados batches de 16 imagens (a rede vê 16 imagens de cada vez durante o treino). \n",
    "#Esse número é para facilitar o processamento conforme a memória do computador durante o treino, colocamos 16 não travar\n",
    "BATCH_SIZE = 16; \n",
    "\n",
    "#Tamanho da imagem e 3 dimensões RGB\n",
    "IMG_SIZE = (224,224,3); \n",
    "if architecture == 'INCEPTION':\n",
    "    IMG_SIZE = (299,299,3);\n",
    "\n",
    "#Seleção do Optimizador\n",
    "optimizer_name = 'SGD'\n",
    "#optimizer_name = 'Adam'\n",
    "\n",
    "#Learning Rate\n",
    "learning_rate = 0.01\n",
    "#learning_rate = 0.0001\n",
    "#learning_rate = 0.001\n",
    "#learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8e378",
   "metadata": {},
   "source": [
    "## Leitura dos nomes dos os arquivos para obtenção dos rótulos (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7630c3d",
   "metadata": {},
   "source": [
    "Cada pasta e arquivo foi nomeado com a classe do budião (Scarus trispinosus_ADT, Scarus zelindae_IP, Sparisoma axillare_IP). Essa função faz a leitura dos nomes para uso (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO PARA LER O NOME DAS CLASSES\n",
    "def get_labels(pasta):\n",
    "    return [name for name in os.listdir(pasta) if os.path.isdir(os.path.join(pasta, name))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUSCA OS NOMES DAS PASTAS\n",
    "trainFolder = 'C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\db\\\\train'\n",
    "valFolder = 'C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\db\\\\val'\n",
    "labels = get_labels(trainFolder)\n",
    "labels = np.array(labels);\n",
    "\n",
    "# Organiza os labels em matriz e salva, para posterior uso em classificação\n",
    "lb = LabelBinarizer();\n",
    "labels = lb.fit_transform(labels);\n",
    "\n",
    "# O arquivo .PICKLE é um arquivo que salva a configuração da rede\n",
    "f = open('C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\budioes_' + architecture + '_' + optimizer_name + '_' + str(learning_rate) + \".pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb));\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4c079",
   "metadata": {},
   "source": [
    "## Otimização da Memória do Computador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21a0c9",
   "metadata": {},
   "source": [
    "ImageDataGenerator = Carrega aos poucos as imagens em memória para fazer a leitura de cada uma, usado para gerenciar os recursos de hardware do computador (para não estourar a memória)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'VGG' or architecture == 'RESNET':\n",
    "    #ImageDataGenerator = objeto para buscar as imagens em uma pasta\n",
    "    #Treino\n",
    "    augTrain = ImageDataGenerator(rotation_range=20, width_shift_range = 0.1, height_shift_range = 0.1, \n",
    "                                  shear_range = 0.15, zoom_range = [1.0, 1.25], horizontal_flip=True, \n",
    "                                  fill_mode=\"nearest\");\n",
    "    #Validação\n",
    "    augVal = ImageDataGenerator();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'INCEPTION':\n",
    "    #ImageDataGenerator = objeto para buscar as imagens em uma pasta\n",
    "    #Treino\n",
    "    #Quando carregar as imagens, será aplicada a função \"preprocess_input\" pré definida pela rede inception\n",
    "    #O \"preprocess_input\" modifica os valores da imagem para facilitar o processamento.\n",
    "    augTrain = ImageDataGenerator(preprocessing_function=preprocess_input, rotation_range=20, width_shift_range = 0.1, height_shift_range = 0.1, \n",
    "                                  shear_range = 0.15, zoom_range = [1.0, 1.25], horizontal_flip=True, \n",
    "                                  fill_mode=\"nearest\");\n",
    "    #Validação\n",
    "    augVal = ImageDataGenerator(preprocessing_function=preprocess_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb4588",
   "metadata": {},
   "source": [
    "# Arquitetura VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff5e505",
   "metadata": {},
   "source": [
    "## Configuração da Rede convolucional (padrão da imagem) e transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2377e27",
   "metadata": {},
   "source": [
    "É feita a declaração da rede VGG (convolution layer e pooling layer) e a aplicação do transfer learning usando a imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'VGG':\n",
    "    #Seleciona somente as camadas de convolução e retreina as de classificação\n",
    "    baseModel = VGG16(include_top=False, weights=\"imagenet\", input_tensor=Input(shape=(224, 224, 3)))\n",
    "    #Como vamos usar imagenet, não faz sentido treinar a rede novamente pois já vamos usar o modelo treinado\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7c264",
   "metadata": {},
   "source": [
    "## Configuração da Rede neural (classificação da imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7cda3f",
   "metadata": {},
   "source": [
    "Configuração das 3 fully connected layers para classificação dos peixes budiões. Elas são organizadas em: primeira camada flatten, 3 conjuntos (dense, ativação e dropout) e a última camada dense (softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'VGG':\n",
    "    #Include_Top configurado manualmente:\n",
    "    #É preciso criar novas camadas (headModel) pra zerar os pesos da VGG\n",
    "    headModel = baseModel.output\n",
    "    headModel = Flatten(name='flatten')(headModel) #(headModel) é o mesmo que concatenar usando o .add\n",
    "    headModel = Dense(4096,  name='fc1')(headModel)\n",
    "    headModel = Activation('relu',  name='act_fc1')(headModel)\n",
    "    #Recurso para evitar overfit (regularização), no caso, 20% dos parâmetros são zeros a cada iteração da rede. \n",
    "    #Isso força a rede a aprender outras formas de classificar\n",
    "    headModel = Dropout(0.2) (headModel)\n",
    "    headModel = Dense(2048,  name='fc2')(headModel)\n",
    "    headModel = Activation('relu',  name='act_fc2')(headModel)\n",
    "    headModel = Dropout(0.2) (headModel)\n",
    "    headModel = Dense(512,  name='fc3')(headModel)\n",
    "    headModel = Activation('relu',  name='act_fc3')(headModel)\n",
    "    headModel = Dropout(0.2) (headModel)\n",
    "    headModel = Dense(len(lb.classes_), activation=\"softmax\", name='predictions')(headModel)\n",
    "    #Junta tudo num modelo só\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b433b0",
   "metadata": {},
   "source": [
    "# Arquitetura ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d4ab1",
   "metadata": {},
   "source": [
    "## Configuração da Rede convolucional (padrão da imagem) e transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c39662",
   "metadata": {},
   "source": [
    "É feita a declaração da rede ResNet (convolution layer e pooling layer) e a aplicação do transfer learning usando a imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'RESNET':\n",
    "    #Declaração da rede RESNET\n",
    "    #Pega só as camadas de convolução e retreina as de classificação\n",
    "    baseModel = ResNet101(include_top=False, weights=\"imagenet\", input_tensor=Input(shape=(224, 224, 3)))\n",
    "    #Como vamos usar imagenet, não faz sentido treinar a rede novamente pois já vamos usar o modelo treinado\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab4ff9",
   "metadata": {},
   "source": [
    "## Configuração da Rede neural (classificação da imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'RESNET':\n",
    "    #Include_Top configurado manualmente:\n",
    "    #É preciso criar novas camadas (headModel) pra zerar os pesos da Resnet\n",
    "    headModel = baseModel.output\n",
    "    headModel = GlobalAveragePooling2D(name=\"avg_pool\")(headModel)\n",
    "    headModel = Dense(len(lb.classes_), activation=\"softmax\", name='predictions')(headModel)\n",
    "    #Junta tudo num modelo só\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f076f28",
   "metadata": {},
   "source": [
    "# Arquitetura Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fd764",
   "metadata": {},
   "source": [
    "## Configuração da Rede convolucional (padrão da imagem) e transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'INCEPTION':\n",
    "    #Declaração da rede INCEPTION V3\n",
    "    #Utiliza somente as camadas de convolução e retreina as de classificação\n",
    "    baseModel = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(299,299,3), pooling='avg') \n",
    "    #Sempre utiliza 3 como parâmetro do input, pois corresponde ao tamanho do RGB da imagem\n",
    "    #Como vamos usar imagenet, não faz sentido treinar a rede novamente pois já vamos usar o modelo treinado\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc106ce",
   "metadata": {},
   "source": [
    "## Configuração da Rede neural (classificação da imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'INCEPTION':\n",
    "    #Include_Top configurado manualmente:\n",
    "    #É preciso criar novas camadas (headModel) pra zerar os pesos da VGG\n",
    "    headModel = baseModel.output\n",
    "    headModel = Dense(len(lb.classes_), activation=\"softmax\", name='predictions')(headModel)\n",
    "    #Junta tudo num modelo só\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef84595",
   "metadata": {},
   "source": [
    "# Execução do treinamento e validação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc141b6",
   "metadata": {},
   "source": [
    "## Aplicação do otimizador de acordo com a definição de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159487a9",
   "metadata": {},
   "source": [
    "Os dois métodos de otimização utilizados são Stochastic Gradient Descent (SGD) ou Método do Gradiente Estocástico e Optimizer Adaptive Moment Estimation (ADAM) ou Estimativa de Momento Adaptativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_name == 'Adam':\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "if optimizer_name == 'SGD':\n",
    "    optimizer = SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reservando espaço de memória para a rede funcionar\n",
    "#Ao final de cada época, será rodado o comando \"callbacks\"\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3db34a",
   "metadata": {},
   "source": [
    "## Preparação dos arquivos de treino e validação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619512be",
   "metadata": {},
   "source": [
    "Função para buscar e configurar as imagens de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c88584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TREINO\n",
    "trainGen = augTrain.flow_from_directory(\n",
    "    trainFolder, #caminho da imagem\n",
    "    class_mode=\"categorical\", #o nome da pasta onde está a imagem será o nome da classe\n",
    "    target_size=(IMG_SIZE[0], IMG_SIZE[1]), #tamanho da imagem a ser redimensionada\n",
    "    color_mode=\"rgb\", #a imagem terá 3 canais RGB\n",
    "    shuffle=True, #vai embaralhar as imagens enquanto faz a leitura\n",
    "    batch_size=BATCH_SIZE); #de quantas em quantas imagens será feita a leitura (tamanho do BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDAÇÃO\n",
    "valGen = augVal.flow_from_directory(\n",
    "    valFolder,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba776d3",
   "metadata": {},
   "source": [
    "## Execução do treinamento e validação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae4b70",
   "metadata": {},
   "source": [
    "O comando model.fit executa o treinamento e validação conforme as configurações definidas anteriormente e salva o melhor resultado entre as épocas (callback) em um arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No nosso modelo, o callback irá salvar o melhor modelo entre as épocas (epochs) - função Model Checkpoint\n",
    "callbacks = [\n",
    "    #ReduceLROnPlateau(monitor = 'val_acc',factor=0.85, patience=10, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint('C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\exemplos\\\\modelo_budioes_' + architecture + '_' + optimizer_name + '_' + str(learning_rate) + \n",
    "                    '-ckpnt.model', save_best_only=True, monitor='val_accuracy', mode='max', verbose = 1)\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_generator vai de fato treinar a rede\n",
    "trained_model = model.fit(trainGen, validation_data=valGen,\n",
    "                        steps_per_epoch=get_images(trainFolder)//BATCH_SIZE,\n",
    "                        validation_steps=get_images(valFolder) // BATCH_SIZE,\n",
    "                        epochs = EPOCHS, callbacks=callbacks, verbose =1);\n",
    "#Dividir o número de imagens pelo número de batchs para garantir que cada BATCH seja lido a cada época\n",
    "#tanto no treino (steps_per_epoch) quanto na validação (validation_steps)\n",
    "#verbose = dá output da rede a cada final de época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salva o modelo (pesos + conexões entre os neurônios, ou seja, a estrutura da rede)\n",
    "model.save('C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\exemplos\\\\modelo_budioes_' + architecture + '_' + optimizer_name + '_' + str(learning_rate) + \".model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8a3b6",
   "metadata": {},
   "source": [
    "## Salvar no formato bentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0331f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo será exportado no formado do bentoML\n",
    "bento_model = bentoml.keras.save_model('modelo_budioes_bentoML_' + architecture + '_' + optimizer_name + '_' + str(learning_rate) +'-ckpnt', model) \n",
    "    print(bento_model.tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
